{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":67356,"databundleVersionId":8006601,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-04T23:44:13.371102Z","iopub.execute_input":"2024-06-04T23:44:13.371511Z","iopub.status.idle":"2024-06-04T23:44:14.561528Z","shell.execute_reply.started":"2024-06-04T23:44:13.371477Z","shell.execute_reply":"2024-06-04T23:44:14.560178Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/leash-BELKA/sample_submission.csv\n/kaggle/input/leash-BELKA/train.parquet\n/kaggle/input/leash-BELKA/test.parquet\n/kaggle/input/leash-BELKA/train.csv\n/kaggle/input/leash-BELKA/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install rdkit","metadata":{"execution":{"iopub.status.busy":"2024-06-04T23:44:32.614881Z","iopub.execute_input":"2024-06-04T23:44:32.615585Z","iopub.status.idle":"2024-06-04T23:44:48.135721Z","shell.execute_reply.started":"2024-06-04T23:44:32.615544Z","shell.execute_reply":"2024-06-04T23:44:48.134439Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting rdkit\n  Downloading rdkit-2023.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rdkit) (1.26.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from rdkit) (9.5.0)\nDownloading rdkit-2023.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rdkit\nSuccessfully installed rdkit-2023.9.6\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install duckdb","metadata":{"execution":{"iopub.status.busy":"2024-06-04T23:45:01.880659Z","iopub.execute_input":"2024-06-04T23:45:01.881115Z","iopub.status.idle":"2024-06-04T23:45:14.430338Z","shell.execute_reply.started":"2024-06-04T23:45:01.881076Z","shell.execute_reply":"2024-06-04T23:45:14.428726Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: duckdb in /opt/conda/lib/python3.10/site-packages (1.0.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import duckdb\nimport pandas as pd\n\ntrain_path = '/kaggle/input/leash-BELKA/train.parquet'\ntest_path = '/kaggle/input/leash-BELKA/test.parquet'\n\ncon = duckdb.connect()\n\ndf = con.query(f\"\"\"(SELECT *\n                        FROM parquet_scan('{train_path}')\n                        WHERE binds = 0\n                        ORDER BY random()\n                        LIMIT 30000)\n                        UNION ALL\n                        (SELECT *\n                        FROM parquet_scan('{train_path}')\n                        WHERE binds = 1\n                        ORDER BY random()\n                        LIMIT 30000)\"\"\").df()\n\ncon.close()","metadata":{"execution":{"iopub.status.busy":"2024-06-04T23:46:11.781446Z","iopub.execute_input":"2024-06-04T23:46:11.782501Z","iopub.status.idle":"2024-06-04T23:47:06.392682Z","shell.execute_reply.started":"2024-06-04T23:46:11.782460Z","shell.execute_reply":"2024-06-04T23:47:06.391655Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2c4380b5a1b4752b18bcf2b8cb12715"}},"metadata":{}}]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-04T23:47:58.554673Z","iopub.execute_input":"2024-06-04T23:47:58.555531Z","iopub.status.idle":"2024-06-04T23:47:58.579566Z","shell.execute_reply.started":"2024-06-04T23:47:58.555490Z","shell.execute_reply":"2024-06-04T23:47:58.578566Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"          id                              buildingblock1_smiles  \\\n0  294525461  [N-]=[N+]=NCCC[C@H](NC(=O)OCC1c2ccccc2-c2ccccc...   \n1  217939534       O=C(Nc1ccnc(C(=O)O)c1)OCC1c2ccccc2-c2ccccc21   \n2  228304713  O=C(Nc1nc2ncc(CNc3ccc(C(=O)O)cc3)nc2c(=O)[nH]1...   \n3  244547160  O=C(O)C[C@@H](Cc1ccc(C(F)(F)F)cc1)NC(=O)OCC1c2...   \n4   77429371        O=C(NC1(C(=O)O)CCCC1)OCC1c2ccccc2-c2ccccc21   \n\n            buildingblock2_smiles                      buildingblock3_smiles  \\\n0                   Cc1cc(N)ccc1O                   NCc1ccc(C(=O)N2CCCC2)cc1   \n1        CC(C)(CN)CCS(C)(=O)=O.Cl                         C=C(C)C(=O)NCCN.Cl   \n2  Cl.NCCN1C(=O)SC(=Cc2cccs2)C1=O                      Cl.NCc1nc2cc(F)ccc2o1   \n3             Cl.Cl.NCc1cncc(F)c1          Nc1nc2c(s1)CN(C(=O)OCc1ccccc1)CC2   \n4                 CC1(CCCCN)OCCO1  Cl.NC[C@@H]1C[C@@H]2O[C@H]1[C@H]1C[C@H]12   \n\n                                     molecule_smiles protein_name  binds  \n0  Cc1cc(Nc2nc(NCc3ccc(C(=O)N4CCCC4)cc3)nc(N[C@@H...          sEH      0  \n1  C=C(C)C(=O)NCCNc1nc(NCC(C)(C)CCS(C)(=O)=O)nc(N...          HSA      0  \n2  O=C(N[Dy])c1ccc(NCc2cnc3nc(Nc4nc(NCCN5C(=O)SC(...         BRD4      0  \n3  O=C(C[C@@H](Cc1ccc(C(F)(F)F)cc1)Nc1nc(NCc2cncc...         BRD4      0  \n4  CC1(CCCCNc2nc(NC[C@@H]3C[C@@H]4O[C@H]3[C@H]3C[...          HSA      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>buildingblock1_smiles</th>\n      <th>buildingblock2_smiles</th>\n      <th>buildingblock3_smiles</th>\n      <th>molecule_smiles</th>\n      <th>protein_name</th>\n      <th>binds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>294525461</td>\n      <td>[N-]=[N+]=NCCC[C@H](NC(=O)OCC1c2ccccc2-c2ccccc...</td>\n      <td>Cc1cc(N)ccc1O</td>\n      <td>NCc1ccc(C(=O)N2CCCC2)cc1</td>\n      <td>Cc1cc(Nc2nc(NCc3ccc(C(=O)N4CCCC4)cc3)nc(N[C@@H...</td>\n      <td>sEH</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>217939534</td>\n      <td>O=C(Nc1ccnc(C(=O)O)c1)OCC1c2ccccc2-c2ccccc21</td>\n      <td>CC(C)(CN)CCS(C)(=O)=O.Cl</td>\n      <td>C=C(C)C(=O)NCCN.Cl</td>\n      <td>C=C(C)C(=O)NCCNc1nc(NCC(C)(C)CCS(C)(=O)=O)nc(N...</td>\n      <td>HSA</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>228304713</td>\n      <td>O=C(Nc1nc2ncc(CNc3ccc(C(=O)O)cc3)nc2c(=O)[nH]1...</td>\n      <td>Cl.NCCN1C(=O)SC(=Cc2cccs2)C1=O</td>\n      <td>Cl.NCc1nc2cc(F)ccc2o1</td>\n      <td>O=C(N[Dy])c1ccc(NCc2cnc3nc(Nc4nc(NCCN5C(=O)SC(...</td>\n      <td>BRD4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>244547160</td>\n      <td>O=C(O)C[C@@H](Cc1ccc(C(F)(F)F)cc1)NC(=O)OCC1c2...</td>\n      <td>Cl.Cl.NCc1cncc(F)c1</td>\n      <td>Nc1nc2c(s1)CN(C(=O)OCc1ccccc1)CC2</td>\n      <td>O=C(C[C@@H](Cc1ccc(C(F)(F)F)cc1)Nc1nc(NCc2cncc...</td>\n      <td>BRD4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>77429371</td>\n      <td>O=C(NC1(C(=O)O)CCCC1)OCC1c2ccccc2-c2ccccc21</td>\n      <td>CC1(CCCCN)OCCO1</td>\n      <td>Cl.NC[C@@H]1C[C@@H]2O[C@H]1[C@H]1C[C@H]12</td>\n      <td>CC1(CCCCNc2nc(NC[C@@H]3C[C@@H]4O[C@H]3[C@H]3C[...</td>\n      <td>HSA</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from rdkit import Chem\nfrom rdkit.Chem import AllChem\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Convert SMILES to RDKit molecules\ndf['molecule'] = df['molecule_smiles'].apply(Chem.MolFromSmiles)\n\n# Generate ECFPs\ndef generate_ecfp(molecule, radius=2, bits=1024):\n    if molecule is None:\n        return None\n    return list(AllChem.GetMorganFingerprintAsBitVect(molecule, radius, nBits=bits))\n\ndf['ecfp'] = df['molecule'].apply(generate_ecfp)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T23:52:47.229931Z","iopub.execute_input":"2024-06-04T23:52:47.230374Z","iopub.status.idle":"2024-06-04T23:54:13.254551Z","shell.execute_reply.started":"2024-06-04T23:52:47.230325Z","shell.execute_reply":"2024-06-04T23:54:13.253630Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# One-hot encode the protein_name\nonehot_encoder = OneHotEncoder(sparse_output=False)\nprotein_onehot = onehot_encoder.fit_transform(df['protein_name'].values.reshape(-1, 1))\n\n# Combine ECFPs and one-hot encoded protein_name\nX = [ecfp + protein for ecfp, protein in zip(df['ecfp'].tolist(), protein_onehot.tolist())]\ny = df['binds'].tolist()\n\n# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create and train the random forest model\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_model.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred_proba = rf_model.predict_proba(X_test)[:, 1]  # Probability of the positive class\n\n# Calculate the mean average precision\nmap_score = average_precision_score(y_test, y_pred_proba)\nprint(f\"Mean Average Precision (mAP): {map_score:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-04T23:57:48.061961Z","iopub.execute_input":"2024-06-04T23:57:48.062444Z","iopub.status.idle":"2024-06-04T23:58:28.793236Z","shell.execute_reply.started":"2024-06-04T23:57:48.062393Z","shell.execute_reply":"2024-06-04T23:58:28.792074Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Mean Average Precision (mAP): 0.96\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\n# Process the test.parquet file chunk by chunk\ntest_file = '/kaggle/input/leash-BELKA/test.csv'\noutput_file = 'submission.csv'  # Specify the path and filename for the output file\n\n# Read the test.parquet file into a pandas DataFrame\nfor df_test in pd.read_csv(test_file, chunksize=100000):\n\n    # Generate ECFPs for the molecule_smiles\n    df_test['molecule'] = df_test['molecule_smiles'].apply(Chem.MolFromSmiles)\n    df_test['ecfp'] = df_test['molecule'].apply(generate_ecfp)\n\n    # One-hot encode the protein_name\n    protein_onehot = onehot_encoder.transform(df_test['protein_name'].values.reshape(-1, 1))\n\n    # Combine ECFPs and one-hot encoded protein_name\n    X_test = [ecfp + protein for ecfp, protein in zip(df_test['ecfp'].tolist(), protein_onehot.tolist())]\n\n    # Predict the probabilities\n    probabilities = rf_model.predict_proba(X_test)[:, 1]\n\n    # Create a DataFrame with 'id' and 'probability' columns\n    output_df = pd.DataFrame({'id': df_test['id'], 'binds': probabilities})\n\n    # Save the output DataFrame to a CSV file\n    output_df.to_csv(output_file, index=False, mode='a', header=not os.path.exists(output_file))","metadata":{"execution":{"iopub.status.busy":"2024-06-05T00:00:40.465770Z","iopub.execute_input":"2024-06-05T00:00:40.466264Z","iopub.status.idle":"2024-06-05T00:42:42.733949Z","shell.execute_reply.started":"2024-06-05T00:00:40.466227Z","shell.execute_reply":"2024-06-05T00:42:42.732701Z"},"trusted":true},"execution_count":12,"outputs":[]}]}